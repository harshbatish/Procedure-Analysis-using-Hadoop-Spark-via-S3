(base)
user@LAPTOP-JH75U6IV MINGW64 ~
$ ssh -i spark_nov.pem hadoop@ec2-3-144-102-165.us-east-2.compute.amazonaws.com Warning: Identity file spark_nov.pem not accessible: No such file or directory.
The authenticity of host 'ec2-3-144-102-165.us-east-2.compute.amazonaws.com (3.144.102.165)' can't be established.
ED25519 key fingerprint is SHA256:uRczRSmq81nKwPNfFrKf3/OA2qpVlckgFdmDe9/68+o.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? no
Host key verification failed.
(base)
user@LAPTOP-JH75U6IV MINGW64 ~
$ cd desktop
(base)
user@LAPTOP-JH75U6IV MINGW64 ~/desktop
$ ssh -i spark_nov.pem hadoop@ec2-3-144-102-165.us-east-2.compute.amazonaws.com
The authenticity of host 'ec2-3-144-102-165.us-east-2.compute.amazonaws.com (3.144.102.165)' can't be established.
ED25519 key fingerprint is SHA256:uRczRSmq81nKwPNfFrKf3/OA2qpVlckgFdmDe9/68+o.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added 'ec2-3-144-102-165.us-east-2.compute.amazonaws.com' (ED25519) to the list of known hosts.
Last login: Fri Dec  2 21:54:20 2022

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
79 package(s) needed for security, out of 113 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -lsr
lsr: DEPRECATED: Please use 'ls -R' instead.
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls -R
[hadoop@ip-172-31-15-205 ~]$ client_loop: send disconnect: Connection reset by peer
hh(base)
user@LAPTOP-JH75U6IV MINGW64 ~/desktop
$ ssh -i spark_nov.pem hadoop@ec2-3-144-102-165.us-east-2.compute.amazonaws.com
Last login: Fri Dec  2 23:52:07 2022

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
79 package(s) needed for security, out of 113 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-172-31-15-205 ~]$ [hadoop@ip-172-31-15-205 ~]$
-bash: [hadoop@ip-172-31-15-205: command not found
[hadoop@ip-172-31-15-205 ~]$ [hadoop@ip-172-31-15-205 ~]$
-bash: [hadoop@ip-172-31-15-205: command not found
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -mkdir /user/<username>/dirname
-bash: username: No such file or directory
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -mkdir /user/hadoop/eng_1M_1gram
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls
Found 1 items
drwxr-xr-x   - hadoop hadoop          0 2022-12-02 23:56 eng_1M_1gram
[hadoop@ip-172-31-15-205 ~]$ hadoop distcp s3://brainstation-dsft/eng_1M_1gram.csv /user/hadoop/eng_1M_1gram/eng_1M_1gram.csv
2022-12-03 00:00:34,547 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, overwrite=false, append=false, useDiff=false, useRdiff=false, fromSnapshot=null, toSnapshot=null, skipCRC=false, blocking=true, numListstatusThreads=0, maxMaps=20, mapBandwidth=0.0, copyStrategy='uniformsize', preserveStatus=[BLOCKSIZE], atomicWorkPath=null, logPath=null, sourceFileListing=null, sourcePaths=[s3://brainstation-dsft/eng_1M_1gram.csv], targetPath=/user/hadoop/eng_1M_1gram/eng_1M_1gram.csv, filtersFile='null', blocksPerChunk=0, copyBufferSize=8192, verboseLog=false, directWrite=false}, sourcePaths=[s3://brainstation-dsft/eng_1M_1gram.csv], targetPathExists=false, preserveRawXattrsfalse
2022-12-03 00:00:34,821 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-15-205.us-east-2.compute.internal/172.31.15.205:8032
2022-12-03 00:00:34,998 INFO client.AHSProxy: Connecting to Application History server at ip-172-31-15-205.us-east-2.compute.internal/172.31.15.205:10200
2022-12-03 00:00:38,517 INFO tools.SimpleCopyListing: Paths (files+dirs) cnt = 1; dirCnt = 0
2022-12-03 00:00:38,517 INFO tools.SimpleCopyListing: Build file listing completed.
2022-12-03 00:00:38,519 INFO Configuration.deprecation: io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2022-12-03 00:00:38,519 INFO Configuration.deprecation: io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2022-12-03 00:00:38,981 INFO tools.DistCp: Number of paths in the copy list: 1
2022-12-03 00:00:39,013 INFO tools.DistCp: Number of paths in the copy list: 1
2022-12-03 00:00:39,038 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-15-205.us-east-2.compute.internal/172.31.15.205:8032
2022-12-03 00:00:39,038 INFO client.AHSProxy: Connecting to Application History server at ip-172-31-15-205.us-east-2.compute.internal/172.31.15.205:10200
2022-12-03 00:00:39,102 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1670016207855_0002
2022-12-03 00:00:39,231 INFO mapreduce.JobSubmitter: number of splits:1
2022-12-03 00:00:39,377 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1670016207855_0002
2022-12-03 00:00:39,379 INFO mapreduce.JobSubmitter: Executing with tokens: []
2022-12-03 00:00:39,543 INFO conf.Configuration: resource-types.xml not found
2022-12-03 00:00:39,543 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-12-03 00:00:39,601 INFO impl.YarnClientImpl: Submitted application application_1670016207855_0002
2022-12-03 00:00:39,644 INFO mapreduce.Job: The url to track the job: http://ip-172-31-15-205.us-east-2.compute.internal:20888/proxy/application_1670016207855_0002/
2022-12-03 00:00:39,645 INFO tools.DistCp: DistCp job-id: job_1670016207855_0002
2022-12-03 00:00:39,645 INFO mapreduce.Job: Running job: job_1670016207855_0002
2022-12-03 00:00:44,729 INFO mapreduce.Job: Job job_1670016207855_0002 running in uber mode : false
2022-12-03 00:00:44,730 INFO mapreduce.Job:  map 0% reduce 0%
2022-12-03 00:01:01,808 INFO mapreduce.Job:  map 100% reduce 0%
2022-12-03 00:01:45,966 INFO mapreduce.Job: Job job_1670016207855_0002 completed successfully
2022-12-03 00:01:46,043 INFO mapreduce.Job: Counters: 42
        File System Counters
                FILE: Number of bytes read=0
                FILE: Number of bytes written=243209
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=375
                HDFS: Number of bytes written=5292105197
                HDFS: Number of read operations=14
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=5
                HDFS: Number of bytes read erasure-coded=0
                S3: Number of bytes read=5292105197
                S3: Number of bytes written=0
                S3: Number of read operations=0
                S3: Number of large read operations=0
                S3: Number of write operations=0
        Job Counters
                Launched map tasks=1
                Other local map tasks=1
                Total time spent by all maps in occupied slots (ms)=5540256
                Total time spent by all reduces in occupied slots (ms)=0
                Total time spent by all map tasks (ms)=57711
                Total vcore-milliseconds taken by all map tasks=57711
                Total megabyte-milliseconds taken by all map tasks=177288192
        Map-Reduce Framework
                Map input records=1
                Map output records=0
                Input split bytes=136
                Spilled Records=0
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=296
                CPU time spent (ms)=61810
                Physical memory (bytes) snapshot=1007480832
                Virtual memory (bytes) snapshot=4427022336
                Total committed heap usage (bytes)=752353280
                Peak Map Physical memory (bytes)=1016238080
                Peak Map Virtual memory (bytes)=4427022336
        File Input Format Counters
                Bytes Read=239
        File Output Format Counters
                Bytes Written=0
        DistCp Counters
                Bandwidth in Btyes=96220094
                Bytes Copied=5292105197
                Bytes Expected=5292105197
                Files Copied=1
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls
Found 1 items
drwxr-xr-x   - hadoop hadoop          0 2022-12-03 00:01 eng_1M_1gram
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -lsr
lsr: DEPRECATED: Please use 'ls -R' instead.
drwxr-xr-x   - hadoop hadoop          0 2022-12-03 00:01 eng_1M_1gram
-rw-r--r--   1 hadoop hadoop 5292105197 2022-12-03 00:01 eng_1M_1gram/eng_1M_1gram.csv
[hadoop@ip-172-31-15-205 ~]$ pwd
/home/hadoop
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram/
Found 1 items
-rw-r--r--   1 hadoop hadoop 5292105197 2022-12-03 00:01 /user/hadoop/eng_1M_1gram/eng_1M_1gram.csv
[hadoop@ip-172-31-15-205 ~]$ client_loop: send disconnect: Connection reset by peer
(base)
user@LAPTOP-JH75U6IV MINGW64 ~/desktop
$ ssh -i spark_nov.pem hadoop@ec2-3-144-102-165.us-east-2.compute.amazonaws.com
Last login: Sat Dec  3 18:50:53 2022

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
79 package(s) needed for security, out of 113 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls
Found 2 items
drwxr-xr-x   - hadoop hadoop          0 2022-12-03 00:01 eng_1M_1gram
drwxr-xr-x   - livy   hadoop          0 2022-12-03 18:16 eng_1M_1gram2
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -lsr
lsr: DEPRECATED: Please use 'ls -R' instead.
drwxr-xr-x   - hadoop hadoop          0 2022-12-03 00:01 eng_1M_1gram
-rw-r--r--   1 hadoop hadoop 5292105197 2022-12-03 00:01 eng_1M_1gram/eng_1M_1gram.csv
drwxr-xr-x   - livy   hadoop          0 2022-12-03 18:16 eng_1M_1gram2
drwxr-xr-x   - livy   hadoop          0 2022-12-03 18:17 eng_1M_1gram2/datatoken.csv
-rw-r--r--   1 livy   hadoop          0 2022-12-03 18:17 eng_1M_1gram2/datatoken.csv/_SUCCESS
-rw-r--r--   1 livy   hadoop         33 2022-12-03 18:16 eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
-rw-r--r--   1 livy   hadoop       7305 2022-12-03 18:16 eng_1M_1gram2/datatoken.csv/part-00023-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
[hadoop@ip-172-31-15-205 ~]$ ^C
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram/
Found 1 items
-rw-r--r--   1 hadoop hadoop 5292105197 2022-12-03 00:01 /user/hadoop/eng_1M_1gram/eng_1M_1gram.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram2/
Found 1 items
drwxr-xr-x   - livy hadoop          0 2022-12-03 18:17 /user/hadoop/eng_1M_1gram2/datatoken.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram/
Found 2 items
drwxr-xr-x   - livy   hadoop          0 2022-12-03 19:24 /user/hadoop/eng_1M_1gram/datatoken.csv
-rw-r--r--   1 hadoop hadoop 5292105197 2022-12-03 00:01 /user/hadoop/eng_1M_1gram/eng_1M_1gram.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls
Found 2 items
drwxr-xr-x   - hadoop hadoop          0 2022-12-03 19:23 eng_1M_1gram
drwxr-xr-x   - livy   hadoop          0 2022-12-03 18:16 eng_1M_1gram2
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -lsr
lsr: DEPRECATED: Please use 'ls -R' instead.
drwxr-xr-x   - hadoop hadoop          0 2022-12-03 19:23 eng_1M_1gram
drwxr-xr-x   - livy   hadoop          0 2022-12-03 19:24 eng_1M_1gram/datatoken.csv
-rw-r--r--   1 livy   hadoop          0 2022-12-03 19:24 eng_1M_1gram/datatoken.csv/_SUCCESS
-rw-r--r--   1 livy   hadoop         33 2022-12-03 19:23 eng_1M_1gram/datatoken.csv/part-00000-54220dee-592f-45ea-b69a-6d0a14c8f500-c000.csv
-rw-r--r--   1 livy   hadoop       7305 2022-12-03 19:24 eng_1M_1gram/datatoken.csv/part-00023-54220dee-592f-45ea-b69a-6d0a14c8f500-c000.csv
-rw-r--r--   1 hadoop hadoop 5292105197 2022-12-03 00:01 eng_1M_1gram/eng_1M_1gram.csv
drwxr-xr-x   - livy   hadoop          0 2022-12-03 18:16 eng_1M_1gram2
drwxr-xr-x   - livy   hadoop          0 2022-12-03 18:17 eng_1M_1gram2/datatoken.csv
-rw-r--r--   1 livy   hadoop          0 2022-12-03 18:17 eng_1M_1gram2/datatoken.csv/_SUCCESS
-rw-r--r--   1 livy   hadoop         33 2022-12-03 18:16 eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
-rw-r--r--   1 livy   hadoop       7305 2022-12-03 18:16 eng_1M_1gram2/datatoken.csv/part-00023-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge ^C
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge /user/hadoop/eng_1M_1gram2/datatoken.csv
-getmerge: Not enough arguments: expected 2 but got 1
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-v] [-x] <path> ...]
        [-expunge [-immediate]]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-head <file>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] [-s <sleep interval>] <file>]
        [-test -[defswrz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -getmerge [-nl] [-skip-empty-file] <src> <localdst>
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge /user/hadoop/eng_1M_1gram2/datatoken.csv /user/hadoop/eng_1M_1gram/eng_1M_gram.csv mergedfile.csv
getmerge: `/user/hadoop/eng_1M_1gram/eng_1M_gram.csv': No such file or directory
[hadoop@ip-172-31-15-205 ~]$ hadoop fs /user/hadoop/eng_1M_1gram/
/user/hadoop/eng_1M_1gram/: Unknown command
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-v] [-x] <path> ...]
        [-expunge [-immediate]]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-head <file>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] [-s <sleep interval>] <file>]
        [-test -[defswrz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram/
Found 2 items
drwxr-xr-x   - livy   hadoop          0 2022-12-03 19:24 /user/hadoop/eng_1M_1gram/datatoken.csv
-rw-r--r--   1 hadoop hadoop 5292105197 2022-12-03 00:01 /user/hadoop/eng_1M_1gram/eng_1M_1gram.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge /user/hadoop/eng_1M_1gram2/datatoken.csv /user/hadoop/eng_1M_1gram/eng_1M_gram.csv mergedfile.csv
getmerge: `/user/hadoop/eng_1M_1gram/eng_1M_gram.csv': No such file or directory
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge /user/hadoop/eng_1M_1gram2/datatoken.csv /user/hadoop/eng_1M_1gram/eng_1M_1gram.csv mergedfile.csv
Exception in thread "main" org.apache.hadoop.fs.FSError: java.io.IOException: No space left on device
        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:280)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
        at java.io.FilterOutputStream.close(FilterOutputStream.java:158)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:73)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:102)
        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.close(ChecksumFileSystem.java:417)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:73)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:102)
        at org.apache.hadoop.fs.shell.CopyCommands$Merge.processArguments(CopyCommands.java:113)
        at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
        at org.apache.hadoop.fs.shell.Command.run(Command.java:177)
        at org.apache.hadoop.fs.FsShell.run(FsShell.java:327)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
        at org.apache.hadoop.fs.FsShell.main(FsShell.java:390)
Caused by: java.io.IOException: No space left on device
        at java.io.FileOutputStream.writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:326)
        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:278)
        ... 15 more
[hadoop@ip-172-31-15-205 ~]$ ^C
[hadoop@ip-172-31-15-205 ~]$ public long getTotalSpace()
-bash: syntax error near unexpected token `('
[hadoop@ip-172-31-15-205 ~]$ public long getTotalSpace
-bash: public: command not found
[hadoop@ip-172-31-15-205 ~]$ ubuntu@ip-*-*-*-*:/tmp/hadoop-ubuntu/mapred/local/localRunner/ubuntu/jobcache
-bash: ubuntu@ip-*-*-*-*:/tmp/hadoop-ubuntu/mapred/local/localRunner/ubuntu/jobcache: No such file or directory
[hadoop@ip-172-31-15-205 ~]$ hadoop fs - ls /user/hadoop/eng_1M_1gram2/datatoken.csv/
ls: Unknown command
Did you mean -ls?  This command begins with a dash.
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-v] [-x] <path> ...]
        [-expunge [-immediate]]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-head <file>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] [-s <sleep interval>] <file>]
        [-test -[defswrz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram2/datatoken.csv/
Found 3 items
-rw-r--r--   1 livy hadoop          0 2022-12-03 18:17 /user/hadoop/eng_1M_1gram2/datatoken.csv/_SUCCESS
-rw-r--r--   1 livy hadoop         33 2022-12-03 18:16 /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
-rw-r--r--   1 livy hadoop       7305 2022-12-03 18:16 /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00023-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge ^C
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
-getmerge: Not enough arguments: expected 2 but got 1
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-v] [-x] <path> ...]
        [-expunge [-immediate]]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-head <file>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] [-s <sleep interval>] <file>]
        [-test -[defswrz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

Usage: hadoop fs [generic options] -getmerge [-nl] [-skip-empty-file] <src> <localdst>
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
getmerge: Mkdirs failed to create file:/user/hadoop/eng_1M_1gram2/datatoken.csv (exists=false, cwd=file:/home/hadoop)
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -getmerge /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00023-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv mergedfile.csv
[hadoop@ip-172-31-15-205 ~]$ cat mergedfile.csv
token,year,frequency,pages,books
token,year,frequency,pages,books
data,1584,16,14,1
data,1614,3,2,1
data,1627,1,1,1
data,1631,22,18,1
data,1637,1,1,1
data,1638,2,2,1
data,1640,1,1,1
data,1642,1,1,1
data,1644,4,4,1
data,1647,1,1,1
data,1651,1,1,1
data,1674,1,1,1
data,1690,1,1,1
data,1693,1,1,1
data,1697,1,1,1
data,1699,1,1,1
data,1700,1,1,1
data,1701,11,11,2
data,1702,1,1,1
data,1703,1,1,1
data,1705,3,3,1
data,1707,2,2,2
data,1708,1,1,1
data,1709,1,1,1
data,1711,4,4,4
data,1713,40,28,1
data,1714,3,3,3
data,1715,1,1,1
data,1717,1,1,1
data,1718,1,1,1
data,1720,7,7,3
data,1722,1,1,1
data,1723,1,1,1
data,1724,2,2,2
data,1725,1,1,1
data,1726,1,1,1
data,1727,11,11,4
data,1728,5,5,5
data,1729,4,4,3
data,1730,17,14,10
data,1731,15,15,4
data,1732,4,3,1
data,1734,1,1,1
data,1735,2,2,2
data,1736,2,2,2
data,1737,4,4,4
data,1738,4,4,3
data,1739,4,4,4
data,1740,3,3,2
data,1742,5,4,4
data,1743,5,5,5
data,1744,1,1,1
data,1745,2,2,2
data,1746,3,3,2
data,1747,11,11,8
data,1748,8,8,6
data,1749,2,2,2
data,1750,6,6,6
data,1751,35,20,6
data,1752,12,12,7
data,1753,8,6,6
data,1754,20,17,11
data,1755,13,12,10
data,1756,5,5,3
data,1757,17,17,9
data,1758,16,13,7
data,1759,18,18,9
data,1760,6,6,5
data,1761,17,15,6
data,1762,10,8,6
data,1763,13,12,7
data,1764,8,8,2
data,1765,6,6,5
data,1766,163,100,21
data,1767,13,13,7
data,1768,19,16,13
data,1769,7,7,5
data,1770,39,34,16
data,1771,38,37,12
data,1772,20,19,11
data,1773,64,46,13
data,1774,46,34,13
data,1775,14,14,12
data,1776,9,9,8
data,1777,57,57,28
data,1778,21,21,13
data,1779,23,19,13
data,1780,28,28,13
data,1781,16,16,9
data,1782,19,19,9
data,1783,16,16,14
data,1784,31,29,19
data,1785,40,39,19
data,1786,50,50,23
data,1787,53,51,35
data,1788,106,102,39
data,1789,38,36,26
data,1790,67,64,41
data,1791,52,48,33
data,1792,83,75,32
data,1793,103,93,45
data,1794,153,139,55
data,1795,85,83,43
data,1796,98,94,47
data,1797,122,94,40
data,1798,64,61,37
data,1799,120,111,56
data,1800,175,172,87
data,1801,256,246,134
data,1802,118,115,59
data,1803,274,271,157
data,1804,336,320,144
data,1805,191,190,125
data,1806,266,258,162
data,1807,349,330,154
data,1808,352,334,180
data,1809,391,368,159
data,1810,263,236,137
data,1811,736,689,268
data,1812,535,503,190
data,1813,273,261,158
data,1814,707,662,217
data,1815,597,548,221
data,1816,490,467,225
data,1817,668,612,257
data,1818,654,619,278
data,1819,683,637,281
data,1820,676,640,271
data,1821,580,547,254
data,1822,1270,1158,375
data,1823,728,702,305
data,1824,1061,990,484
data,1825,1291,1188,450
data,1826,1031,950,375
data,1827,1118,1051,387
data,1828,1497,1333,448
data,1829,1711,1574,513
data,1830,1879,1736,539
data,1831,1700,1533,536
data,1832,1822,1692,568
data,1833,1887,1742,568
data,1834,2070,1914,599
data,1835,2059,1924,681
data,1836,2322,2092,730
data,1837,2150,2004,652
data,1838,2055,1875,672
data,1839,2684,2365,796
data,1840,2240,2056,716
data,1841,2291,2121,705
data,1842,1993,1797,583
data,1843,2231,2008,729
data,1844,2202,2056,757
data,1845,2229,2082,687
data,1846,2582,2355,832
data,1847,2654,2423,834
data,1848,3061,2808,873
data,1849,3411,2903,906
data,1850,3744,3363,955
data,1851,3506,3207,1017
data,1852,3934,3591,1149
data,1853,4336,3913,1263
data,1854,5219,4457,1170
data,1855,4886,4447,1144
data,1856,3985,3589,1123
data,1857,3958,3641,1152
data,1858,3756,3425,1022
data,1859,4221,3877,1133
data,1860,5107,4532,1184
data,1861,2788,2511,863
data,1862,2802,2597,825
data,1863,2947,2651,799
data,1864,3471,3218,1023
data,1865,3614,3274,1023
data,1866,4715,4169,1123
data,1867,4327,3902,1104
data,1868,3951,3539,1076
data,1869,4664,4179,1118
data,1870,4408,3942,1126
data,1871,5627,4834,1181
data,1872,5587,4952,1235
data,1873,6235,5386,1274
data,1874,7409,6549,1429
data,1875,6919,5997,1492
data,1876,6609,5974,1574
data,1877,6651,5931,1459
data,1878,5975,5037,1419
data,1879,6535,5890,1607
data,1880,6673,6016,1804
data,1881,7745,6904,1876
data,1882,7533,6696,1813
data,1883,9174,8054,1964
data,1884,8368,7294,1981
data,1885,9036,7955,2017
data,1886,9393,8202,1926
data,1887,7827,6901,1945
data,1888,10544,8608,2006
data,1889,11864,9809,1991
data,1890,9731,8431,1994
data,1891,10768,9301,2049
data,1892,10034,8825,2092
data,1893,10959,9375,2011
data,1894,10344,8868,1966
data,1895,8816,7621,1900
data,1896,9127,7947,1975
data,1897,10074,8709,2003
data,1898,10418,8797,1934
data,1899,19519,13503,2024
data,1900,9462,8213,1965
data,1901,10200,8887,1941
data,1902,11006,9613,2031
data,1903,11931,10305,2099
data,1904,12509,10636,2249
data,1905,40085,22447,2440
data,1906,15051,12399,2338
data,1907,16804,13852,2260
data,1908,16849,13728,2338
data,1909,15448,12720,2506
data,1910,17557,14229,2341
data,1911,19787,16080,2558
data,1912,19537,15924,2606
data,1913,18948,15749,2692
data,1914,20216,16239,2621
data,1915,24523,18866,2754
data,1916,22930,18543,2631
data,1917,26256,19801,2637
data,1918,25227,19156,2565
data,1919,23440,17733,2577
data,1920,25161,19437,2793
data,1921,29222,22150,2877
data,1922,32344,25190,2903
data,1923,33126,24414,2722
data,1924,35383,25893,2808
data,1925,38260,27030,2814
data,1926,42025,30204,2957
data,1927,37173,27683,2928
data,1928,40612,29647,2920
data,1929,39671,28490,2986
data,1930,41694,30193,3072
data,1931,45581,32792,3144
data,1932,51244,34997,3178
data,1933,46972,33300,3144
data,1934,47385,32903,3121
data,1935,44778,31812,3168
data,1936,46543,32266,3092
data,1937,51809,36473,3244
data,1938,59987,40816,3370
data,1939,64879,43637,3504
data,1940,59462,41686,3422
data,1941,64402,44180,3476
data,1942,57783,41137,3425
data,1943,57474,39406,3446
data,1944,52409,36613,3141
data,1945,50404,35987,3275
data,1946,50772,35015,3171
data,1947,57153,39594,3337
data,1948,62065,42955,3430
data,1949,73263,50278,3603
data,1950,73906,50254,3544
data,1951,71638,48794,3580
data,1952,77497,51897,3730
data,1953,83570,55061,3682
data,1954,87482,56365,3639
data,1955,83134,54313,3560
data,1956,87781,55768,3685
data,1957,80924,52794,3617
data,1958,85048,55407,3708
data,1959,101148,63448,3820
data,1960,98764,61849,3809
data,1961,114753,68445,3783
data,1962,101633,63269,3807
data,1963,108256,64705,3736
data,1964,112466,67874,3773
data,1965,113951,69461,3858
data,1966,112346,67025,3793
data,1967,110933,66940,3837
data,1968,116721,69066,3800
data,1969,121693,69128,3770
data,1970,123934,72270,3864
data,1971,143455,80684,3889
data,1972,150624,84185,3999
data,1973,151772,85843,4101
data,1974,159902,89566,4108
data,1975,158046,87718,4070
data,1976,183442,96766,4180
data,1977,173943,93897,4200
data,1978,184030,99110,4138
data,1979,204964,106616,4259
data,1980,204041,105491,4194
data,1981,205932,109572,4287
data,1982,211927,108269,4325
data,1983,228551,114594,4366
data,1984,222158,115055,4372
data,1985,226011,114070,4287
data,1986,252018,122472,4368
data,1987,249908,119628,4319
data,1988,245294,117292,4323
data,1989,231870,113240,4266
data,1990,221227,110155,4267
data,1991,241856,114701,4240
data,1992,254561,119790,4237
data,1993,223635,111014,4303
data,1994,236845,110670,4180
data,1995,216659,108378,4315
data,1996,213991,108023,4284
data,1997,223109,110021,4264
data,1998,208230,104315,4231
data,1999,230573,108982,4179
data,2000,223813,107134,4040
data,2001,247209,115258,3983
data,2002,241848,109219,3825
data,2003,244250,105400,3684
data,2004,201841,93539,3483
data,2005,197467,88901,3392
data,2006,203669,92960,3449
data,2007,168338,78986,3246
data,2008,105331,47811,2358
[hadoop@ip-172-31-15-205 ~]$ client_loop: send disconnect: Connection reset by peer
(base)
user@LAPTOP-JH75U6IV MINGW64 ~/desktop
$ ssh -i spark_nov.pem hadoop@ec2-3-144-102-165.us-east-2.compute.amazonaws.com
Last login: Sat Dec  3 20:16:57 2022

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
79 package(s) needed for security, out of 113 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram2/
Found 1 items
drwxr-xr-x   - livy hadoop          0 2022-12-03 18:17 /user/hadoop/eng_1M_1gram2/datatoken.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls /user/hadoop/eng_1M_1gram2/datatoken.csv/
Found 3 items
-rw-r--r--   1 livy hadoop          0 2022-12-03 18:17 /user/hadoop/eng_1M_1gram2/datatoken.csv/_SUCCESS
-rw-r--r--   1 livy hadoop         33 2022-12-03 18:16 /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00000-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
-rw-r--r--   1 livy hadoop       7305 2022-12-03 18:16 /user/hadoop/eng_1M_1gram2/datatoken.csv/part-00023-88ec2ae9-7637-400c-91f3-9f67125cfc84-c000.csv
[hadoop@ip-172-31-15-205 ~]$ hadoop fs -ls
Found 2 items
drwxr-xr-x   - hadoop hadoop          0 2022-12-03 19:23 eng_1M_1gram
drwxr-xr-x   - livy   hadoop          0 2022-12-03 18:16 eng_1M_1gram2
[hadoop@ip-172-31-15-205 ~]$ client_loop: send disconnect: Connection reset by peer
(base)
user@LAPTOP-JH75U6IV MINGW64 ~/desktop
$ ssh -i spark_nov.pem hadoop@ec2-3-144-102-165.us-east-2.compute.amazonaws.com
Last login: Sat Dec  3 20:52:17 2022

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
79 package(s) needed for security, out of 113 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-172-31-15-205 ~]$ aws s3 cp mergedfile.csv https://us-east-1.console.aws.amazon.com/s3/buckets/forbigdata3?region=us-east-2/mergedfile.csv

usage: aws s3 cp <LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>
Error: Invalid argument type
[hadoop@ip-172-31-15-205 ~]$ aws s3 cp mergedfile.csv s3://forbigdata3
upload: ./mergedfile.csv to s3://forbigdata3/mergedfile.csv
[hadoop@ip-172-31-15-205 ~]$ aws configure
AWS Access Key ID [None]:
AWS Secret Access Key [None]:
Default region name [None]:
Default output format [None]:
[hadoop@ip-172-31-15-205 ~]$ aws configure
AWS Access Key ID [None]: AKIAVY65SSOZESHNXWJ7
AWS Secret Access Key [None]: 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
Default region name [None]:
Default output format [None]:
[hadoop@ip-172-31-15-205 ~]$ client_loop: send disconnect: Connection reset by peer
(base)
user@LAPTOP-JH75U6IV MINGW64 ~/desktop
$ ssh -i spark_nov.pem hadoop@ec2-3-144-102-165.us-east-2.compute.amazonaws.com
ssh: connect to host ec2-3-144-102-165.us-east-2.compute.amazonaws.com port 22: Connection timed out
(base)
user@LAPTOP-JH75U6IV MINGW64 ~/desktop
$
